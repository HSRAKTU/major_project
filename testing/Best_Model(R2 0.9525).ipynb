{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218ba7f2",
   "metadata": {},
   "source": [
    "# Importing Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcd0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Imports and Seed Setup\n",
    "# -----------------------------\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # for saving the scaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41516c9c",
   "metadata": {},
   "source": [
    "# Pepraring Scaler Function and Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a83241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler mean: 0.284506, std: 0.037448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../outputs/cd_scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1.2. Prepaing Scaler\n",
    "# -----------------------------\n",
    "\n",
    "df = pd.read_csv('..\\data\\DrivAerNetPlusPlus_Drag_8k_cleaned.csv')\n",
    "\n",
    "# Subset to only training car IDs\n",
    "with open(\"../data/subset_dir/train_design_ids.txt\") as f:\n",
    "    train_ids = [line.strip() for line in f]\n",
    "\n",
    "df_train = df[df[\"Design\"].isin(train_ids)]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train[[\"Average Cd\"]])\n",
    "\n",
    "print(f\"Scaler mean: {scaler.mean_[0]:.6f}, std: {scaler.scale_[0]:.6f}\")\n",
    "\n",
    "# Save scaler to disk\n",
    "os.makedirs(\"../outputs\", exist_ok=True)\n",
    "joblib.dump(scaler, \"../outputs/cd_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0d7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1.3. Global Variables\n",
    "# -----------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "point_net_input_dim = 2\n",
    "point_net_embedding_dim = 256\n",
    "lstm_input_dim = point_net_embedding_dim\n",
    "lstm_hidden_dim = 256\n",
    "bidirectional = True\n",
    "number_of_layers = 2\n",
    "cd_regressor_input_dim = lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim\n",
    "batch_size = 4\n",
    "\n",
    "model_checkpoint_dir=\"../outputs/checkpoints3\"\n",
    "analysis_output_dir='../outputs/analysis'\n",
    "\n",
    "scaler = joblib.load(\"../outputs/cd_scaler.pkl\")\n",
    "assert hasattr(scaler, \"mean_\"), \"Scaler not loaded correctly\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da915d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e42f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# LightPointNet2D: Efficient 2D PointNet\n",
    "# -----------------------------\n",
    "class PointNet2D(nn.Module):\n",
    "    def __init__(self, input_dim=2, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 32, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(32, 64, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, emb_dim, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (B*N, P, 2) → (B*N, 2, P)\n",
    "        x = x.transpose(1, 2)  # (B, 2, N)\n",
    "        features = self.mlp(x)  # (B, emb_dim, N)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # (B, 1, N)\n",
    "            features = features.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # Global max pooling\n",
    "        embedding = torch.max(features, dim=2)[0]  # (B, emb_dim)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0225096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. LSTM Slice Encoder (Optimized)\n",
    "# -----------------------------\n",
    "class LSTMSliceEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=512, hidden_dim=512, num_layers=2, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=0.2  # Dropout between layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input and model are on the same device\n",
    "        assert x.device == next(self.parameters()).device, \"Input and model are on different devices!\"\n",
    "\n",
    "        # x: (B, S, D)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        if self.lstm.bidirectional:\n",
    "            return torch.cat((h_n[-2], h_n[-1]), dim=-1)  # (B, 2H)\n",
    "        else:\n",
    "            return h_n[-1]  # (B, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824a7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Cd Regressor MLP (Optimized)\n",
    "# -----------------------------\n",
    "class CdRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=1024):  # 512 * 2 from BiLSTM\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input and model are on the same device\n",
    "        assert x.device == next(self.parameters()).device, \"Input and model are on different devices!\"\n",
    "        return self.net(x).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3870d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5. Full Model Assembly (Optimized)\n",
    "# -----------------------------\n",
    "class CdPredictorNet(nn.Module):\n",
    "    def __init__(self, pointnet, lstm_encoder, regressor):\n",
    "        super().__init__()\n",
    "        self.pointnet = pointnet\n",
    "        self.lstm_encoder = lstm_encoder\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def forward(self, slices, point_mask, slice_mask):\n",
    "        # slices: (B, S, N, D)\n",
    "        B, S, N, D = slices.shape\n",
    "\n",
    "        # Optional: Device consistency check\n",
    "        assert slices.device == next(self.parameters()).device, \"Input slices not on same device as model.\"\n",
    "\n",
    "        # Flatten slices and masks\n",
    "        flat_slices = slices.reshape(B * S, N, D)\n",
    "        flat_mask = point_mask.reshape(B * S, N)\n",
    "\n",
    "        # Encode each slice\n",
    "        slice_embs = self.pointnet(flat_slices, flat_mask)  # (B*S, 256)\n",
    "        slice_embs = slice_embs.view(B, S, -1)  # (B, S, 256)\n",
    "\n",
    "        # Temporal encoding with LSTM\n",
    "        car_emb = self.lstm_encoder(slice_embs)  # (B, 1024 if bidirectional)\n",
    "\n",
    "        # Final regression\n",
    "        return self.regressor(car_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fcc65",
   "metadata": {},
   "source": [
    "# Dataset loader and Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385df74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6. Dataset Loader (Optimized)\n",
    "# -----------------------------\n",
    "class CarSlicesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids_txt, npz_dir, csv_path, max_cars=None, scaler = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ids_txt (str): Path to the text file containing car IDs.\n",
    "            npz_dir (str): Directory containing the .npz files.\n",
    "            csv_path (str): Path to the CSV file with Cd values.\n",
    "            max_cars (int, optional): Limit the number of cars to load. Defaults to None.\n",
    "            scaler (object, optional): Scaler object for normalizing Cd values. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.car_ids = [line.strip() for line in open(ids_txt)]\n",
    "        if max_cars:\n",
    "            self.car_ids = self.car_ids[:max_cars]\n",
    "        self.npz_dir = npz_dir\n",
    "        self.cd_map = pd.read_csv(csv_path).set_index(\"Design\")[\"Average Cd\"].to_dict()\n",
    "        self.scaler = scaler if scaler else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.car_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        car_id = self.car_ids[idx]\n",
    "        data = np.load(os.path.join(self.npz_dir, f\"{car_id}_axis-x.npz\"))\n",
    "\n",
    "        # Keep in NumPy for now (better for pin_memory and batch collation)\n",
    "        slices = data[\"slices\"].astype(np.float32)         # (80, 6500, 2)\n",
    "        point_mask = data[\"point_mask\"].astype(np.float32) # (80, 6500)\n",
    "        slice_mask = data[\"slice_mask\"].astype(np.float32) # (80,)\n",
    "        cd_value = np.float32(self.cd_map[car_id])\n",
    "\n",
    "        if self.scaler:\n",
    "            cd_value = self.scaler.transform([[cd_value]])[0, 0]\n",
    "\n",
    "        return slices, point_mask, slice_mask, cd_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ec6e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CdPredictorNet                           [4]                       --\n",
       "├─PointNet2D: 1-1                        [320, 256]                --\n",
       "│    └─Sequential: 2-1                   [320, 256, 6500]          --\n",
       "│    │    └─Conv1d: 3-1                  [320, 32, 6500]           96\n",
       "│    │    └─ReLU: 3-2                    [320, 32, 6500]           --\n",
       "│    │    └─Conv1d: 3-3                  [320, 64, 6500]           2,112\n",
       "│    │    └─ReLU: 3-4                    [320, 64, 6500]           --\n",
       "│    │    └─Conv1d: 3-5                  [320, 256, 6500]          16,640\n",
       "│    │    └─ReLU: 3-6                    [320, 256, 6500]          --\n",
       "├─LSTMSliceEncoder: 1-2                  [4, 512]                  --\n",
       "│    └─LSTM: 2-2                         [4, 80, 512]              2,629,632\n",
       "├─CdRegressor: 1-3                       [4]                       --\n",
       "│    └─Sequential: 2-3                   [4, 1]                    --\n",
       "│    │    └─Linear: 3-7                  [4, 256]                  131,328\n",
       "│    │    └─ReLU: 3-8                    [4, 256]                  --\n",
       "│    │    └─Dropout: 3-9                 [4, 256]                  --\n",
       "│    │    └─Linear: 3-10                 [4, 64]                   16,448\n",
       "│    │    └─ReLU: 3-11                   [4, 64]                   --\n",
       "│    │    └─Linear: 3-12                 [4, 1]                    65\n",
       "==========================================================================================\n",
       "Total params: 2,796,321\n",
       "Trainable params: 2,796,321\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 40.05\n",
       "==========================================================================================\n",
       "Input size (MB): 24.96\n",
       "Forward/backward pass size (MB): 5858.60\n",
       "Params size (MB): 11.19\n",
       "Estimated Total Size (MB): 5894.75\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create model\n",
    "pointnet = PointNet2D(input_dim=point_net_input_dim, emb_dim=point_net_embedding_dim)\n",
    "lstm_encoder = LSTMSliceEncoder(input_dim=lstm_input_dim, hidden_dim=lstm_hidden_dim, num_layers=number_of_layers, bidirectional=bidirectional)\n",
    "regressor = CdRegressor(input_dim=cd_regressor_input_dim)\n",
    "model = CdPredictorNet(pointnet, lstm_encoder, regressor).to(device)\n",
    "\n",
    "# Print model summary (example input: batch_size=2, slices=80, points=6500, dim=2)\n",
    "summary(model, input_data=(\n",
    "    torch.zeros(batch_size, 80, 6500, 2).to(device),\n",
    "    torch.ones(batch_size, 80, 6500).to(device),\n",
    "    torch.ones(batch_size, 80).to(device)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75f8f7",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0a613",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9c6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def evaluate_model(model, val_loader, device, scaler):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for slices, point_mask, slice_mask, cd_gt in val_loader:\n",
    "            slices = slices.to(device, non_blocking=True)\n",
    "            point_mask = point_mask.to(device, non_blocking=True)\n",
    "            slice_mask = slice_mask.to(device, non_blocking=True)\n",
    "            cd_gt = cd_gt.to(device, non_blocking=True).float()\n",
    "\n",
    "            pred = model(slices, point_mask, slice_mask)\n",
    "            preds.append(pred)\n",
    "            trues.append(cd_gt)\n",
    "\n",
    "    preds = torch.cat(preds).cpu().numpy()\n",
    "    trues = torch.cat(trues).cpu().numpy()\n",
    "\n",
    "    if scaler:\n",
    "        preds = scaler.inverse_transform(preds.reshape(-1, 1)).flatten()\n",
    "        trues = scaler.inverse_transform(trues.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Metrics\n",
    "    r2 = r2_score(trues, preds)\n",
    "    mse = mean_squared_error(trues, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(trues, preds)\n",
    "    mape = np.mean(np.abs((trues - preds) / (trues + 1e-8))) * 100  # small constant for stability\n",
    "\n",
    "    # Normalized Absolute Error (based on range)\n",
    "    value_range = np.max(trues) - np.min(trues)\n",
    "    nmae = np.mean(np.abs(trues - preds) / (value_range + 1e-8))\n",
    "\n",
    "    print(f\"\\n📊 Validation Metrics:\")\n",
    "    print(f\"🔹 R²   = {r2:.4f}\")\n",
    "    print(f\"🔹 MSE  = {mse:.6f}\")\n",
    "    print(f\"🔹 RMSE = {rmse:.6f}\")\n",
    "    print(f\"🔹 MAE  = {mae:.6f}\")\n",
    "    print(f\"🔹 MAPE = {mape:.2f}%\")\n",
    "    print(f\"🔹 NMAE  = {nmae:.4f}\")\n",
    "    print(f\"⏱️ Time taken: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    return {\"r2\": r2, \"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"mape\": mape, \"nmae\": nmae}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92019c9a",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7b25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7. Training Loop (Updated)\n",
    "# -----------------------------\n",
    "\n",
    "def train_model(resume=True, num_epochs=50, max_cars=2000, validation_set_size=200,\n",
    "                checkpoint_dir=model_checkpoint_dir, early_stopping_patience=5):\n",
    "    import time\n",
    "\n",
    "    # Initialize model using global config\n",
    "    pointnet = PointNet2D(input_dim=point_net_input_dim, emb_dim=point_net_embedding_dim)\n",
    "    lstm_encoder = LSTMSliceEncoder(\n",
    "        input_dim=lstm_input_dim,\n",
    "        hidden_dim=lstm_hidden_dim,\n",
    "        num_layers=number_of_layers,\n",
    "        bidirectional=bidirectional\n",
    "    )\n",
    "    regressor = CdRegressor(input_dim=cd_regressor_input_dim)\n",
    "    model = CdPredictorNet(pointnet, lstm_encoder, regressor).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    start_epoch = 1\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    # Resume from checkpoint if available\n",
    "    if resume:\n",
    "        checkpoints = sorted(glob.glob(os.path.join(checkpoint_dir, \"epoch_*_loss*.pt\")))\n",
    "        if checkpoints:\n",
    "            latest_ckpt = checkpoints[-1]\n",
    "            print(f\"🔄 Resuming from checkpoint: {latest_ckpt}\")\n",
    "            state = torch.load(latest_ckpt, map_location=device)\n",
    "            model.load_state_dict(state['model'])\n",
    "            optimizer.load_state_dict(state['optimizer'])\n",
    "            start_epoch = state['epoch'] + 1\n",
    "            epoch_losses = state.get('epoch_losses', [])\n",
    "            best_loss = min(epoch_losses) if epoch_losses else float(\"inf\")\n",
    "        else:\n",
    "            print(\"⏩ No previous checkpoint found, starting fresh.\")\n",
    "\n",
    "    # Dataset & Dataloaders\n",
    "    train_dataset = CarSlicesDataset(\n",
    "        ids_txt=\"../data/subset_dir/train_design_ids.txt\",\n",
    "        npz_dir=\"../outputs/pad_masked_slices\",\n",
    "        csv_path=\"../data/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "        max_cars=max_cars,\n",
    "        scaler=scaler\n",
    "    )\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_dataset = CarSlicesDataset(\n",
    "        ids_txt=\"../data/subset_dir/val_design_ids.txt\",\n",
    "        npz_dir=\"../outputs/pad_masked_slices\",\n",
    "        csv_path=\"../data/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "        max_cars=validation_set_size,\n",
    "        scaler=scaler\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    print(f\"📦 Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples.\")\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, num_epochs + 1):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            start_time = time.time()\n",
    "            pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "\n",
    "            for slices, point_mask, slice_mask, cd_gt in pbar:\n",
    "\n",
    "                slices = slices.to(device, non_blocking=True)\n",
    "                point_mask = point_mask.to(device, non_blocking=True)\n",
    "                slice_mask = slice_mask.to(device, non_blocking=True)\n",
    "                cd_gt = cd_gt.to(device, non_blocking=True).float()\n",
    "\n",
    "                pred = model(slices, point_mask, slice_mask)\n",
    "                loss = loss_fn(pred, cd_gt)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss = loss.item() * slices.size(0)\n",
    "                total_loss += batch_loss\n",
    "                pbar.set_postfix(loss=batch_loss / slices.size(0))\n",
    "\n",
    "            avg_loss = total_loss / len(train_dataloader.dataset)\n",
    "            epoch_losses.append(avg_loss)\n",
    "            print(f\"\\n✅ Epoch {epoch}: Avg SmoothL1 Loss = {avg_loss:.7f}\")\n",
    "\n",
    "            # 🔍 Validation\n",
    "            print(f\"🔍 Evaluating on validation set:\")\n",
    "            evaluate_model(model, val_loader, device, scaler)\n",
    "\n",
    "            print(f\"⏱️ Epoch Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "            # 💾 Save checkpoint\n",
    "            ckpt_path = os.path.join(checkpoint_dir, f\"epoch_{epoch:02d}_loss_{avg_loss:.8f}.pt\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch_losses': epoch_losses\n",
    "            }, ckpt_path)\n",
    "            print(f\"💾 Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "            # 🏆 Save best model separately\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pt\"))\n",
    "                print(\"🏆 Best model updated.\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping_patience:\n",
    "                    print(f\"🛑 Early stopping at epoch {epoch}.\")\n",
    "                    break\n",
    "\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⛔ Interrupted. Saving checkpoint...\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch_losses': epoch_losses\n",
    "        }, os.path.join(checkpoint_dir, f\"interrupted_epoch_{epoch}.pt\"))\n",
    "        print(\"🧷 Last checkpoint saved.\")\n",
    "\n",
    "    return model, epoch_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f8fb3",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8541b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_log = train_model(\n",
    "#     resume=True,                        # Set to True if you want to continue from a saved checkpoint\n",
    "#     num_epochs=100,\n",
    "#     max_cars=None,                       # Use entire dataset\n",
    "#     checkpoint_dir=model_checkpoint_dir,\n",
    "#     early_stopping_patience=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92070095",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7648dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_all_checkpoints(checkpoint_dir=\"../outputs/temp_checkpoints\", output_dir=\"../outputs/temp_analysis\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint_paths = sorted(glob.glob(os.path.join(checkpoint_dir, \"epoch_*.pt\")))\n",
    "    all_epoch_losses = []\n",
    "    epoch_numbers = []\n",
    "\n",
    "    print(\"\\n📋 Epoch-wise Loss Summary:\")\n",
    "    for ckpt_path in checkpoint_paths:\n",
    "        try:\n",
    "            checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "            losses = checkpoint.get(\"epoch_losses\", [])\n",
    "            epoch = checkpoint.get(\"epoch\", None)\n",
    "\n",
    "            if epoch is not None and losses:\n",
    "                epoch_numbers.append(epoch)\n",
    "                last_loss = losses[-1]\n",
    "                all_epoch_losses.append(last_loss)\n",
    "                print(f\"Epoch {epoch:02d} → Loss: {last_loss:.7f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipped {ckpt_path}: {e}\")\n",
    "\n",
    "    if not epoch_numbers:\n",
    "        print(\"❌ No valid checkpoints found.\")\n",
    "        return\n",
    "\n",
    "    # Save compiled loss log\n",
    "    loss_log_path = os.path.join(output_dir, \"compiled_epoch_losses.json\")\n",
    "    with open(loss_log_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"epoch_numbers\": epoch_numbers,\n",
    "            \"epoch_losses\": all_epoch_losses\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n📄 Saved compiled loss log to: {loss_log_path}\")\n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.lineplot(x=epoch_numbers, y=all_epoch_losses, marker=\"o\")\n",
    "    plt.title(\"📉 Training Loss Curve from Checkpoints\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"SmoothL1 Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"loss_curve_from_ckpts.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot deltas\n",
    "    if len(all_epoch_losses) > 1:\n",
    "        loss_deltas = [all_epoch_losses[i] - all_epoch_losses[i-1] for i in range(1, len(all_epoch_losses))]\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=epoch_numbers[1:], y=loss_deltas)\n",
    "        plt.title(\"📊 Δ Loss Between Checkpoints\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Δ Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"loss_deltas_from_ckpts.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"✅ Done analyzing {len(epoch_numbers)} checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc6bb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Epoch-wise Loss Summary:\n",
      "Epoch 01 → Loss: 0.1635625\n",
      "Epoch 02 → Loss: 0.1042404\n",
      "Epoch 03 → Loss: 0.0837441\n",
      "Epoch 04 → Loss: 0.0860357\n",
      "Epoch 05 → Loss: 0.0824505\n",
      "Epoch 06 → Loss: 0.0715279\n",
      "Epoch 07 → Loss: 0.0671776\n",
      "Epoch 08 → Loss: 0.0637395\n",
      "Epoch 09 → Loss: 0.0586883\n",
      "Epoch 100 → Loss: 0.0171010\n",
      "Epoch 10 → Loss: 0.0572876\n",
      "Epoch 11 → Loss: 0.0540730\n",
      "Epoch 12 → Loss: 0.0495315\n",
      "Epoch 13 → Loss: 0.0461043\n",
      "Epoch 14 → Loss: 0.0459189\n",
      "Epoch 15 → Loss: 0.0455986\n",
      "Epoch 16 → Loss: 0.0438680\n",
      "Epoch 17 → Loss: 0.0424614\n",
      "Epoch 18 → Loss: 0.0422533\n",
      "Epoch 19 → Loss: 0.0410204\n",
      "Epoch 20 → Loss: 0.0398268\n",
      "Epoch 21 → Loss: 0.0387932\n",
      "Epoch 22 → Loss: 0.0394746\n",
      "Epoch 23 → Loss: 0.0366771\n",
      "Epoch 24 → Loss: 0.0372471\n",
      "Epoch 25 → Loss: 0.0361738\n",
      "Epoch 26 → Loss: 0.0356182\n",
      "Epoch 27 → Loss: 0.0354190\n",
      "Epoch 28 → Loss: 0.0344296\n",
      "Epoch 29 → Loss: 0.0343859\n",
      "Epoch 30 → Loss: 0.0342555\n",
      "Epoch 31 → Loss: 0.0338324\n",
      "Epoch 32 → Loss: 0.0330284\n",
      "Epoch 33 → Loss: 0.0329009\n",
      "Epoch 34 → Loss: 0.0323607\n",
      "Epoch 35 → Loss: 0.0316003\n",
      "Epoch 36 → Loss: 0.0311263\n",
      "Epoch 37 → Loss: 0.0321633\n",
      "Epoch 38 → Loss: 0.0339353\n",
      "Epoch 39 → Loss: 0.0292123\n",
      "Epoch 40 → Loss: 0.0292795\n",
      "Epoch 41 → Loss: 0.0308955\n",
      "Epoch 42 → Loss: 0.0300664\n",
      "Epoch 43 → Loss: 0.0289722\n",
      "Epoch 44 → Loss: 0.0290949\n",
      "Epoch 45 → Loss: 0.0279314\n",
      "Epoch 46 → Loss: 0.0280627\n",
      "Epoch 47 → Loss: 0.0427236\n",
      "Epoch 48 → Loss: 0.0295611\n",
      "Epoch 49 → Loss: 0.0304807\n",
      "Epoch 50 → Loss: 0.0278559\n",
      "Epoch 51 → Loss: 0.0277185\n",
      "Epoch 52 → Loss: 0.0274563\n",
      "Epoch 53 → Loss: 0.0260659\n",
      "Epoch 54 → Loss: 0.0260880\n",
      "Epoch 55 → Loss: 0.0274180\n",
      "Epoch 56 → Loss: 0.0249533\n",
      "Epoch 57 → Loss: 0.0255746\n",
      "Epoch 58 → Loss: 0.0250147\n",
      "Epoch 59 → Loss: 0.0241582\n",
      "Epoch 60 → Loss: 0.0240544\n",
      "Epoch 61 → Loss: 0.0240707\n",
      "Epoch 62 → Loss: 0.0238014\n",
      "Epoch 63 → Loss: 0.0231216\n",
      "Epoch 64 → Loss: 0.0226095\n",
      "Epoch 65 → Loss: 0.0236224\n",
      "Epoch 66 → Loss: 0.0221054\n",
      "Epoch 67 → Loss: 0.0224088\n",
      "Epoch 68 → Loss: 0.0216249\n",
      "Epoch 69 → Loss: 0.0218538\n",
      "Epoch 70 → Loss: 0.0211585\n",
      "Epoch 71 → Loss: 0.0204701\n",
      "Epoch 72 → Loss: 0.0202559\n",
      "Epoch 73 → Loss: 0.0195402\n",
      "Epoch 74 → Loss: 0.0198681\n",
      "Epoch 75 → Loss: 0.0211390\n",
      "Epoch 76 → Loss: 0.0197921\n",
      "Epoch 77 → Loss: 0.0196685\n",
      "Epoch 78 → Loss: 0.0199435\n",
      "Epoch 79 → Loss: 0.0176628\n",
      "Epoch 80 → Loss: 0.0178634\n",
      "Epoch 81 → Loss: 0.0177988\n",
      "Epoch 82 → Loss: 0.0173280\n",
      "Epoch 83 → Loss: 0.0169254\n",
      "Epoch 84 → Loss: 0.0170735\n",
      "Epoch 85 → Loss: 0.0176544\n",
      "Epoch 86 → Loss: 0.0166854\n",
      "Epoch 87 → Loss: 0.0161837\n",
      "Epoch 88 → Loss: 0.0150491\n",
      "Epoch 89 → Loss: 0.0160682\n",
      "Epoch 90 → Loss: 0.0158964\n",
      "Epoch 91 → Loss: 0.0149057\n",
      "Epoch 92 → Loss: 0.0144500\n",
      "Epoch 93 → Loss: 0.0154015\n",
      "Epoch 94 → Loss: 0.0143492\n",
      "Epoch 95 → Loss: 0.0141808\n",
      "Epoch 96 → Loss: 0.0138274\n",
      "Epoch 97 → Loss: 0.0156437\n",
      "Epoch 98 → Loss: 0.0147878\n",
      "Epoch 99 → Loss: 0.0151830\n",
      "\n",
      "📄 Saved compiled loss log to: ../outputs/analysis\\compiled_epoch_losses.json\n",
      "✅ Done analyzing 100 checkpoints\n"
     ]
    }
   ],
   "source": [
    "analyze_all_checkpoints(checkpoint_dir=model_checkpoint_dir, output_dir=analysis_output_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d33701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 Loaded best model from: ../outputs/checkpoints3\\epoch_68_loss_0.02162494.pt\n"
     ]
    }
   ],
   "source": [
    "def load_best_model(model_checkpoint_dir = model_checkpoint_dir):\n",
    "    \"\"\"\n",
    "    Loads the best model saved in `best_model.pt` using global architecture settings.\n",
    "    \"\"\"\n",
    "    best_model_path = os.path.join(model_checkpoint_dir, \"epoch_68_loss_0.02162494.pt\")\n",
    "\n",
    "    # Recreate model architecture using global config\n",
    "    pointnet = PointNet2D(input_dim=point_net_input_dim, emb_dim=point_net_embedding_dim)\n",
    "    lstm_encoder = LSTMSliceEncoder(\n",
    "        input_dim=lstm_input_dim,\n",
    "        hidden_dim=lstm_hidden_dim,\n",
    "        num_layers=number_of_layers,\n",
    "        bidirectional=bidirectional\n",
    "    )\n",
    "    regressor = CdRegressor(input_dim=cd_regressor_input_dim)\n",
    "    best_model = CdPredictorNet(pointnet, lstm_encoder, regressor).to(device)\n",
    "\n",
    "    if os.path.exists(best_model_path):\n",
    "        best_model.load_state_dict(torch.load(best_model_path, map_location=device)['model'])\n",
    "        best_model.eval()\n",
    "        print(f\"🏆 Loaded best model from: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"❌ No best_model.pt found at: {best_model_path}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "temp_model = load_best_model(model_checkpoint_dir)  # New clean instance, separate from training-time model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42696ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating on test_design_ids:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Evaluating cars: 100%|███████████████████| 1158/1158 [00:41<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Summary:\n",
      "🔹 R² Score     : 0.9525\n",
      "🔹 MSE          : 0.000066\n",
      "🔹 RMSE         : 0.008148\n",
      "🔹 MAE          : 0.006111\n",
      "🔹 MAPE         : 2.23%\n",
      "🔹 NMAE         : 3.5821\n",
      "🔹 Cars tested  : 1158 / 1158\n",
      "🔹 Avg inference time: 0.024985 sec\n",
      "💾 Saved predictions to: ../outputs/eval2\\cd_predictions_test_design_ids.csv\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Evaluating on val_design_ids:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Evaluating cars: 100%|███████████████████| 1157/1157 [00:39<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Summary:\n",
      "🔹 R² Score     : 0.9443\n",
      "🔹 MSE          : 0.000072\n",
      "🔹 RMSE         : 0.008498\n",
      "🔹 MAE          : 0.006335\n",
      "🔹 MAPE         : 2.32%\n",
      "🔹 NMAE         : 3.6480\n",
      "🔹 Cars tested  : 1157 / 1157\n",
      "🔹 Avg inference time: 0.024226 sec\n",
      "💾 Saved predictions to: ../outputs/eval2\\cd_predictions_val_design_ids.csv\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Evaluating on train_design_ids:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔄 Evaluating cars: 100%|███████████████████| 5398/5398 [03:20<00:00, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Summary:\n",
      "🔹 R² Score     : 0.9678\n",
      "🔹 MSE          : 0.000045\n",
      "🔹 RMSE         : 0.006718\n",
      "🔹 MAE          : 0.005104\n",
      "🔹 MAPE         : 1.86%\n",
      "🔹 NMAE         : 2.8016\n",
      "🔹 Cars tested  : 5398 / 5398\n",
      "🔹 Avg inference time: 0.024327 sec\n",
      "💾 Saved predictions to: ../outputs/eval2\\cd_predictions_train_design_ids.csv\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Assumes temp_model and scaler are already loaded\n",
    "assert temp_model is not None, \"temp_model is not loaded.\"\n",
    "assert hasattr(scaler, \"scale_\") and hasattr(scaler, \"mean_\"), \"Scaler must have 'scale_' and 'mean_' attributes\"\n",
    "\n",
    "temp_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_amp = torch.cuda.is_available()\n",
    "if use_amp:\n",
    "    from torch.cuda.amp import autocast\n",
    "\n",
    "# Input splits\n",
    "id_files = [\n",
    "    \"../data/subset_dir/test_design_ids.txt\",\n",
    "    \"../data/subset_dir/val_design_ids.txt\",\n",
    "    \"../data/subset_dir/train_design_ids.txt\"\n",
    "]\n",
    "\n",
    "# Ground-truth Cd values\n",
    "df = pd.read_csv(\"../data/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\")\n",
    "cd_map = dict(zip(df[\"Design\"], df[\"Average Cd\"]))\n",
    "\n",
    "eval_dir = \"../outputs/eval2\"\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "for id_file in id_files:\n",
    "    split_name = os.path.basename(id_file).replace(\".txt\", \"\")\n",
    "    filename = f\"cd_predictions_{split_name}.csv\"\n",
    "    out_path = os.path.join(eval_dir, filename)\n",
    "\n",
    "    print(f\"\\n🔍 Evaluating on {split_name}:\")\n",
    "\n",
    "    with open(id_file) as f:\n",
    "        test_ids = [line.strip() for line in f]\n",
    "\n",
    "    preds, trues, ids_used, times = [], [], [], []\n",
    "\n",
    "    for car_id in tqdm(test_ids, desc=\"🔄 Evaluating cars\", ncols=80):\n",
    "        npz_path = f\"../outputs/pad_masked_slices/{car_id}_axis-x.npz\"\n",
    "        if not os.path.exists(npz_path):\n",
    "            print(f\"⚠️ Missing file: {car_id}\")\n",
    "            continue\n",
    "\n",
    "        data = np.load(npz_path)\n",
    "        slices = torch.from_numpy(data[\"slices\"]).float().to(device, non_blocking=True).unsqueeze(0)\n",
    "        point_mask = torch.from_numpy(data[\"point_mask\"]).float().to(device, non_blocking=True).unsqueeze(0)\n",
    "        slice_mask = torch.from_numpy(data[\"slice_mask\"]).float().to(device, non_blocking=True).unsqueeze(0)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    cd_scaled = temp_model(slices, point_mask, slice_mask).item()\n",
    "            else:\n",
    "                cd_scaled = temp_model(slices, point_mask, slice_mask).item()\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        cd_pred = (cd_scaled * scaler.scale_[0]) + scaler.mean_[0]\n",
    "\n",
    "        cd_true = cd_map.get(car_id)\n",
    "        if cd_true is None:\n",
    "            print(f\"⚠️ No ground truth for {car_id}\")\n",
    "            continue\n",
    "\n",
    "        preds.append(cd_pred)\n",
    "        trues.append(cd_true)\n",
    "        ids_used.append(car_id)\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    # Convert to NumPy for metrics\n",
    "    preds_np = np.array(preds)\n",
    "    trues_np = np.array(trues)\n",
    "    times_np = np.array(times)\n",
    "\n",
    "    r2 = r2_score(trues_np, preds_np)\n",
    "    mse = mean_squared_error(trues_np, preds_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(trues_np, preds_np)\n",
    "    mape = np.mean(np.abs((trues_np - preds_np) / trues_np)) * 100\n",
    "    nmae = np.mean(np.abs(trues_np - preds_np) / (np.max(trues_np) - np.min(trues_np))) * 100\n",
    "    avg_infer_time = np.mean(times_np)\n",
    "\n",
    "    # Report\n",
    "    print(\"📊 Evaluation Summary:\")\n",
    "    print(f\"🔹 R² Score     : {r2:.4f}\")\n",
    "    print(f\"🔹 MSE          : {mse:.6f}\")\n",
    "    print(f\"🔹 RMSE         : {rmse:.6f}\")\n",
    "    print(f\"🔹 MAE          : {mae:.6f}\")\n",
    "    print(f\"🔹 MAPE         : {mape:.2f}%\")\n",
    "    print(f\"🔹 NMAE         : {nmae:.4f}\")\n",
    "    print(f\"🔹 Cars tested  : {len(preds)} / {len(test_ids)}\")\n",
    "    print(f\"🔹 Avg inference time: {avg_infer_time:.6f} sec\")\n",
    "\n",
    "    # Save predictions\n",
    "    pd.DataFrame({\n",
    "        \"Design ID\": ids_used,\n",
    "        \"Predicted Cd\": preds,\n",
    "        \"True Cd\": trues\n",
    "    }).to_csv(out_path, index=False)\n",
    "    print(f\"💾 Saved predictions to: {out_path}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu-copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
