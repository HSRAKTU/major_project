{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path to one valid .npz file from your dataset\n",
    "car_path = \"outputs/pad_masked_slices/DrivAer_F_D_WM_WW_0005_axis-x.npz\"\n",
    "data = np.load(car_path)\n",
    "\n",
    "slices = data[\"slices\"]           # (80, 6500, 2)\n",
    "point_mask = data[\"point_mask\"]   # (80, 6500)\n",
    "slice_mask = data[\"slice_mask\"]   # (80,)\n",
    "\n",
    "# Find the first real slice (non-zero in slice_mask)\n",
    "slice_idx = int(np.argmax(slice_mask))\n",
    "\n",
    "slice_points = slices[slice_idx]         # (6500, 2)\n",
    "point_mask_slice = point_mask[slice_idx]  # (6500,)\n",
    "\n",
    "print(f\"Using slice #{slice_idx} with {int(point_mask_slice.sum())} valid points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "valid_points = slice_points[point_mask_slice.astype(bool)]\n",
    "plt.scatter(valid_points[:, 0], valid_points[:, 1], s=1)\n",
    "plt.title(f\"Slice #{slice_idx} - (y, z) points\")\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.axis(\"equal\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7991ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet2D(nn.Module):\n",
    "    def __init__(self, input_dim=2, emb_dim=128):\n",
    "        super(PointNet2D, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, emb_dim, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (B, N, 2) â†’ (B, 2, N)\n",
    "        x = x.transpose(1, 2)\n",
    "        features = self.mlp(x)  # (B, emb_dim, N)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # (B, 1, N)\n",
    "            features = features * mask + (1 - mask) * (-1e9)  # safe masked max\n",
    "\n",
    "        embedding = torch.max(features, dim=2)[0]  # (B, emb_dim)\n",
    "        return embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3868b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert slice to tensor\n",
    "slice_tensor = torch.tensor(slice_points, dtype=torch.float32).unsqueeze(0)  # (1, 6500, 2)\n",
    "mask_tensor = torch.tensor(point_mask_slice, dtype=torch.float32).unsqueeze(0)  # (1, 6500)\n",
    "\n",
    "# Create model\n",
    "pointnet = PointNet2D(input_dim=2, emb_dim=128)\n",
    "\n",
    "# Run forward pass\n",
    "embedding = pointnet(slice_tensor, mask_tensor)\n",
    "\n",
    "print(\"Output embedding shape:\", embedding.shape)\n",
    "print(\"Sample embedding:\", embedding)  # show first 5 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMSliceEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim=128, num_layers=1, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,    # slice embedding size\n",
    "            hidden_size=hidden_dim,  # output embedding per car\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,        # input shape: (B, S, D)\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, S, D) â†’ (batch, 80 slices, 128 features)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)  # h_n: (num_layers Ã— num_directions, B, H)\n",
    "\n",
    "        # Get the last layer's hidden state\n",
    "        if self.bidirectional:\n",
    "            # concat forward + backward\n",
    "            h_final = torch.cat((h_n[-2], h_n[-1]), dim=-1)  # (B, 2H)\n",
    "        else:\n",
    "            h_final = h_n[-1]  # (B, H)\n",
    "\n",
    "        return h_final  # this becomes your car-level feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch.nn as nn\n",
    "\n",
    "class CdRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be451f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CarSlicesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ids_txt, npz_dir, csv_path, max_cars=100):\n",
    "        self.car_ids = [line.strip() for line in open(ids_txt)][:max_cars]\n",
    "        self.npz_dir = npz_dir\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.car_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        car_id = self.car_ids[idx]\n",
    "        path = os.path.join(self.npz_dir, f\"{car_id}_axis-x.npz\")\n",
    "        data = np.load(path)\n",
    "\n",
    "        slices = torch.tensor(data[\"slices\"], dtype=torch.float32)          # (80, 6500, 2)\n",
    "        point_mask = torch.tensor(data[\"point_mask\"], dtype=torch.float32)  # (80, 6500)\n",
    "        slice_mask = torch.tensor(data[\"slice_mask\"], dtype=torch.float32)  # (80,)\n",
    "\n",
    "        cd_value = self.df[self.df[\"Design\"] == car_id][\"Average Cd\"].values[0]\n",
    "        return slices, point_mask, slice_mask, torch.tensor(cd_value, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2327e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CdPredictorNet(nn.Module):\n",
    "    def __init__(self, pointnet, lstm_encoder, regressor):\n",
    "        super().__init__()\n",
    "        self.pointnet = pointnet\n",
    "        self.lstm_encoder = lstm_encoder\n",
    "        self.regressor = regressor\n",
    "\n",
    "    def forward(self, slices, point_mask, slice_mask):\n",
    "        B, S, N, D = slices.shape  # (B, 80, 6500, 2)\n",
    "        slices = slices.view(B * S, N, D)\n",
    "        mask = point_mask.view(B * S, N)\n",
    "\n",
    "        # Slice-wise feature extraction (batched)\n",
    "        slice_emb = self.pointnet(slices, mask)  # (BÃ—S, 128)\n",
    "        slice_emb = slice_emb.view(B, S, -1)     # (B, 80, 128)\n",
    "\n",
    "        car_emb = self.lstm_encoder(slice_emb)   # (B, 128 or 256)\n",
    "        cd_pred = self.regressor(car_emb)        # (B,)\n",
    "\n",
    "        return cd_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate model components\n",
    "pointnet = PointNet2D(input_dim=2, emb_dim=128)\n",
    "lstm_encoder = LSTMSliceEncoder(input_dim=128, hidden_dim=128, bidirectional=False)\n",
    "regressor = CdRegressor(input_dim=128)\n",
    "\n",
    "model = CdPredictorNet(pointnet, lstm_encoder, regressor)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = CarSlicesDataset(\n",
    "    ids_txt=\"data/subset_dir/train_design_ids.txt\",\n",
    "    npz_dir=\"outputs/pad_masked_slices\",\n",
    "    csv_path=\"data/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\",\n",
    "    max_cars=100\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "# Optimizer & Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for slices, point_mask, slice_mask, cd_gt in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        slices = slices.to(device)\n",
    "        point_mask = point_mask.to(device)\n",
    "        cd_gt = cd_gt.to(device)\n",
    "\n",
    "        cd_pred = model(slices, point_mask, slice_mask)\n",
    "        loss = loss_fn(cd_pred, cd_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * slices.size(0)\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "    print(f\"âœ… Epoch {epoch+1}: Avg MSE Loss = {avg_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load model\n",
    "model.eval()\n",
    "\n",
    "# Load full training IDs and select test subset (first 10 not used in training)\n",
    "with open(\"data/subset_dir/train_design_ids.txt\") as f:\n",
    "    all_ids = [line.strip() for line in f]\n",
    "\n",
    "test_ids = all_ids[:10]  # Pick 10 early cars\n",
    "\n",
    "# Load CSV to get ground truth Cd\n",
    "df = pd.read_csv(\"data/DrivAerNetPlusPlus_Drag_8k_cleaned.csv\")\n",
    "\n",
    "# Initialize storage\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "# Inference loop\n",
    "for car_id in test_ids:\n",
    "    path = f\"outputs/pad_masked_slices/{car_id}_axis-x.npz\"\n",
    "    data = np.load(path)\n",
    "\n",
    "    slices = torch.tensor(data[\"slices\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    point_mask = torch.tensor(data[\"point_mask\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    slice_mask = torch.tensor(data[\"slice_mask\"], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        cd_pred = model(slices, point_mask, slice_mask).item()\n",
    "    \n",
    "    cd_true = df[df[\"Design\"] == car_id][\"Average Cd\"].values[0]\n",
    "\n",
    "    preds.append(cd_pred)\n",
    "    trues.append(cd_true)\n",
    "\n",
    "    print(f\"ðŸš— {car_id} â†’ Predicted Cd: {cd_pred:.4f} | True Cd: {cd_true:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac557e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(trues, preds)\n",
    "print(f\"\\nðŸ“Š RÂ² Score on 60-car test subset: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load a test car not seen in training\n",
    "car_id = \"F_S_WWC_WM_498\"  # or any from train_design_ids.txt[150:]\n",
    "\n",
    "# Load and convert to tensors\n",
    "data = np.load(f\"outputs/pad_masked_slices/{car_id}_axis-x.npz\")\n",
    "slices = torch.tensor(data[\"slices\"], dtype=torch.float32).unsqueeze(0).to(device)        # (1, 80, 6500, 2)\n",
    "point_mask = torch.tensor(data[\"point_mask\"], dtype=torch.float32).unsqueeze(0).to(device) # (1, 80, 6500)\n",
    "slice_mask = torch.tensor(data[\"slice_mask\"], dtype=torch.float32).unsqueeze(0).to(device) # (1, 80)\n",
    "\n",
    "# Forward pass through full model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"ðŸŸ¦ Input shape:\", slices.shape)\n",
    "\n",
    "    # Step 1: Slice embeddings from PointNet2D\n",
    "    B, S, N, D = slices.shape\n",
    "    flat_slices = slices.view(B * S, N, D)\n",
    "    flat_mask = point_mask.view(B * S, N)\n",
    "    \n",
    "    print(\"ðŸŸ¦ Flattened for PointNet2D:\", flat_slices.shape)\n",
    "    slice_emb = model.pointnet(flat_slices, flat_mask)   # (BÃ—S, 128)\n",
    "    print(\"ðŸŸ¦ Slice embeddings shape:\", slice_emb.shape)\n",
    "\n",
    "    slice_emb = slice_emb.view(B, S, -1)  # (1, 80, 128)\n",
    "    print(\"ðŸŸ¦ Sequence ready for LSTM:\", slice_emb.shape)\n",
    "\n",
    "    # Step 2: LSTM\n",
    "    car_feature = model.lstm_encoder(slice_emb)  # (1, 128)\n",
    "    print(\"ðŸŸ¦ Output of LSTM (car embedding):\", car_feature.shape)\n",
    "\n",
    "    # Step 3: Cd prediction\n",
    "    cd_pred = model.regressor(car_feature)\n",
    "    print(\"ðŸŸ© Final Predicted Cd:\", cd_pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807387e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# slice_emb: shape (80, 128), from your diagnostic pass\n",
    "embedding_np = slice_emb.squeeze(0).cpu().detach().numpy()  # Now shape = (80, 128)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(embedding_np, cmap='viridis', cbar=True)\n",
    "plt.title(\"ðŸ§  Slice-wise Embeddings (80 slices Ã— 128 features)\")\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.ylabel(\"Slice Index (front to rear)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure `slice_emb` is (80, 128) and on CPU\n",
    "slice_emb_np = slice_emb.squeeze(0).cpu().detach().numpy()\n",
    "\n",
    "# Run PCA\n",
    "pca = PCA(n_components=2)\n",
    "slice_pca = pca.fit_transform(slice_emb_np)  # shape: (80, 2)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(slice_pca[:, 0], slice_pca[:, 1], marker='o', linestyle='-', color='steelblue')\n",
    "for i in range(0, 80, 10):\n",
    "    plt.text(slice_pca[i, 0], slice_pca[i, 1], str(i), fontsize=8)\n",
    "\n",
    "plt.title(\"ðŸš— PCA of Slice Embeddings (Front â†’ Rear)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu-copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
